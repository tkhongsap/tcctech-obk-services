{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f7172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.ocr_intel import extract_receipts, create_doc_intel_client\n",
    "from dotenv import dotenv_values\n",
    "import os\n",
    "import json\n",
    "from helper.azure_ai import az_content_understanding_analyze\n",
    "from helper.general_function import combine, validate_receipt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced7eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(source, file_path):\n",
    "    ai_trigger = 0\n",
    "    config = dotenv_values(\".env\")\n",
    "\n",
    "    endpoint = config[\"endpoint_s0_doc_int\"]\n",
    "    key = config[\"key_s0_doc_int\"]\n",
    "\n",
    "    doc_intel_client = create_doc_intel_client(endpoint, key)\n",
    "    if type(source) == str:\n",
    "        extracted_receipts = extract_receipts(\n",
    "            urls=source, document_intelligence_client=doc_intel_client\n",
    "        )\n",
    "    else:\n",
    "        extracted_receipts = extract_receipts(\n",
    "            bytes_source=source, document_intelligence_client=doc_intel_client\n",
    "        )\n",
    "\n",
    "    keys_to_check = [\"total\", \"transaction_date\", \"transaction_time\"]\n",
    "    if any(extracted_receipts[0][key] is None for key in keys_to_check):\n",
    "        ai_trigger += 1\n",
    "        ai_extracted_receipts = az_content_understanding_analyze(file_path)\n",
    "        extracted_receipts = combine(extracted_receipts, ai_extracted_receipts)\n",
    "        extracted_receipts = validate_receipt(extracted_receipts)\n",
    "    \n",
    "    print(ai_trigger)\n",
    "    # return json.dumps(extracted_receipts, indent=4, ensure_ascii=False),ai_trigger\n",
    "    return extracted_receipts,ai_trigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902297ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m file_content = file.read()\n\u001b[32m     11\u001b[39m start_time = datetime.now()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m result, ai_trigger = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m end_time = datetime.now()\n\u001b[32m     14\u001b[39m runtime = (end_time - start_time).total_seconds()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(source, file_path)\u001b[39m\n\u001b[32m     10\u001b[39m     extracted_receipts = extract_receipts(\n\u001b[32m     11\u001b[39m         urls=source, document_intelligence_client=doc_intel_client\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     extracted_receipts = \u001b[43mextract_receipts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbytes_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_intelligence_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoc_intel_client\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m keys_to_check = [\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransaction_date\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransaction_time\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(extracted_receipts[\u001b[32m0\u001b[39m][key] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys_to_check):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phuvit.j\\Desktop\\TCC\\azure-ocr-pipeline\\helper\\ocr_intel.py:78\u001b[39m, in \u001b[36mextract_receipts\u001b[39m\u001b[34m(document_intelligence_client, urls, bytes_source)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# If the source is bytes, use the bytes to extract receipts\u001b[39;00m\n\u001b[32m     68\u001b[39m     poller = document_intelligence_client.begin_analyze_document(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprebuilt-receipt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m         AnalyzeDocumentRequest(bytes_source=bytes_source),\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m         query_fields=[\u001b[33m\"\u001b[39m\u001b[33mTax_Id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mReceipt_No\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMall_Name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnit_No\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     76\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m receipts: AnalyzeResult = \u001b[43mpoller\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m receipts_data = []\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m receipts.documents:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phuvit.j\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:254\u001b[39m, in \u001b[36mLROPoller.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> PollingReturnType_co:\n\u001b[32m    246\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[32m    248\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m \u001b[33;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._polling_method.resource()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phuvit.j\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phuvit.j\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:269\u001b[39m, in \u001b[36mLROPoller.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phuvit.j\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py:1092\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     timeout = \u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "INPUT_PATH = 'data/inputs/receipt_images'\n",
    "\n",
    "total_ai_trigger = 0\n",
    "total_runtime = []\n",
    "file_runtime_dct = {}\n",
    "file_missing_dct = {}\n",
    "for file_name in os.listdir(INPUT_PATH):\n",
    "    file_path = os.path.join(INPUT_PATH,file_name)\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        file_content = file.read()\n",
    "        start_time = datetime.now()\n",
    "        result, ai_trigger = main(file_content,file_path)\n",
    "        end_time = datetime.now()\n",
    "        runtime = (end_time - start_time).total_seconds()\n",
    "        total_runtime.append(runtime)\n",
    "        total_ai_trigger += ai_trigger\n",
    "        file_runtime_dct[file_name] = runtime\n",
    "        file_missing_dct[file_name] = result[0]['invalid_fields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26afe2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send to AzAi: 16/335 images\n",
      "AVG Runtime: 6.086 secs\n",
      "Median Runtime: 4.7925 secs\n",
      "Max Runtime: 45.7092 secs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Send to AzAi: {total_ai_trigger}/{len(total_runtime)} images\")\n",
    "print(f\"AVG Runtime: {round(np.mean(total_runtime),4)} secs\")\n",
    "print(f\"Median Runtime: {round(np.median(total_runtime),4)} secs\")\n",
    "print(f\"Max Runtime: {round(np.max(total_runtime),4)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da62980",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fields = ['tax_id', 'total', 'date', 'time']\n",
    "\n",
    "# Create a list to store the transformed data\n",
    "rows = []\n",
    "\n",
    "for filename, invalid_fields in file_missing_dct.items():\n",
    "    # Start with the filename\n",
    "    row = {'Filename': filename}\n",
    "    \n",
    "    # Add columns for each field\n",
    "    for field in all_fields:\n",
    "        # Set value to 1 if field is in the invalid_fields list, 0 otherwise\n",
    "        column_name = f'invalid_{field}' if field != 'tax_id' else 'invalid_tax_id'\n",
    "        row[column_name] = 1 if field in invalid_fields else 0\n",
    "    \n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "file_missing_fields_df = pd.DataFrame(rows)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_filename = f\"{timestamp}_invalid_fields.csv\"\n",
    "file_missing_fields_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bb4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_id_error_rate = file_missing_fields_df['invalid_tax_id'].sum()/len(file_missing_fields_df) * 100\n",
    "total_error_rate = file_missing_fields_df['invalid_total'].sum()/len(file_missing_fields_df) * 100\n",
    "date_error_rate = file_missing_fields_df['invalid_date'].sum()/len(file_missing_fields_df) * 100\n",
    "time_error_rate = file_missing_fields_df['invalid_time'].sum()/len(file_missing_fields_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ee2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tax_id error rate: 10/335 = 2.9851%\n",
      "total error rate: 3/335 = 0.8955%\n",
      "date error rate: 0/335 = 0.0%\n",
      "time error rate: 0/335 = 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"tax_id error rate: {file_missing_fields_df['invalid_tax_id'].sum()}/{len(file_missing_fields_df)} = {round(tax_id_error_rate,4)}%\")\n",
    "print(f\"total error rate: {file_missing_fields_df['invalid_total'].sum()}/{len(file_missing_fields_df)} = {round(total_error_rate,4)}%\")\n",
    "print(f\"date error rate: {file_missing_fields_df['invalid_date'].sum()}/{len(file_missing_fields_df)} = {round(date_error_rate,4)}%\")\n",
    "print(f\"time error rate: {file_missing_fields_df['invalid_time'].sum()}/{len(file_missing_fields_df)} = {round(time_error_rate,4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7f101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "file_runtime_df = pd.DataFrame(list(file_runtime_dct.items()), columns=['Filename', 'Runtime'])\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_filename = f\"{timestamp}_runtime.csv\"\n",
    "file_runtime_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8f6b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Runtime",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5bde1980-2124-4472-a6b5-240ee2ed9456",
       "rows": [
        [
         "count",
         "335.0"
        ],
        [
         "mean",
         "6.085967647761193"
        ],
        [
         "std",
         "4.803941127383131"
        ],
        [
         "min",
         "2.568122"
        ],
        [
         "25%",
         "3.8406295"
        ],
        [
         "50%",
         "4.792484"
        ],
        [
         "75%",
         "5.3819859999999995"
        ],
        [
         "max",
         "45.709153"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.085968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.803941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.568122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.840629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.792484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.381986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.709153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Runtime\n",
       "count  335.000000\n",
       "mean     6.085968\n",
       "std      4.803941\n",
       "min      2.568122\n",
       "25%      3.840629\n",
       "50%      4.792484\n",
       "75%      5.381986\n",
       "max     45.709153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_runtime_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ec799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
